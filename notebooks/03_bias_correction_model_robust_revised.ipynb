{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53317c6",
   "metadata": {},
   "source": [
    "# 3. Bias Correction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b0a3d-bac3-4fe5-ac47-32d1b3add3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import h3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Path for data loading\n",
    "data_path = '../processed_data/matched_weekly_strava_ecocounter_extended.csv'\n",
    "\n",
    "# Load the file\n",
    "df = pd.read_csv(data_path, parse_dates=['week_start'])\n",
    "\n",
    "df.rename(columns={\n",
    "    'SUM_total_trip_count': 'strava_count',\n",
    "    'EcoCntr_weekly_SUM': 'eco_count'\n",
    "}, inplace=True)\n",
    "\n",
    "# Preview\n",
    "print(df.head())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['eco_count'], kde=True, color='blue', label='EcoCounter')\n",
    "sns.histplot(df['strava_count'], kde=True, color='orange', label='Strava')\n",
    "plt.title('Distribution of Weekly Counts')\n",
    "plt.xlabel('Weekly Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x='strava_count', y='eco_count')\n",
    "plt.title('Strava vs. EcoCounter Weekly Counts')\n",
    "plt.xlabel('Strava Weekly Count')\n",
    "plt.ylabel('EcoCounter Weekly Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "correlation = df[['strava_count', 'eco_count']].corr().iloc[0, 1]\n",
    "print(f\"Correlation between Strava and EcoCounter counts: {correlation:.2f}\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_model = df[['strava_count', 'eco_count']].dropna()\n",
    "\n",
    "X = df_model[['strava_count']]\n",
    "y = df_model['eco_count']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "df_model['eco_pred'] = model.predict(X)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='strava_count', y='eco_count', data=df_model, label='Observed')\n",
    "sns.lineplot(x='strava_count', y='eco_pred', data=df_model, color='red', label='Regression Line')\n",
    "plt.title('Linear Regression: EcoCounter ~ Strava')\n",
    "plt.xlabel('Strava Count')\n",
    "plt.ylabel('EcoCounter Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y, df_model['eco_pred']))\n",
    "print(f\"üìâ RMSE: {rmse:.2f}\")\n",
    "\n",
    "# üì¶ Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ‚úÖ Set up plotting\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# --- üìÅ Load Data ---\n",
    "data_path = \"/home/jovyan/BiasCorrectionCrowdsourcedData-cookbook/processed_data/weekly_with_covariates.csv\"\n",
    "df = pd.read_csv(data_path, parse_dates=[\"week_start\"])\n",
    "\n",
    "# ‚úÖ Rename for consistency\n",
    "df = df.rename(columns={\n",
    "    \"SUM_total_trip_count\": \"strava_count\",\n",
    "    \"EcoCntr_weekly_SUM\": \"ecocounter_count\"\n",
    "})\n",
    "df[\"total_count\"] = df[\"strava_count\"] + df[\"ecocounter_count\"]\n",
    "\n",
    "# üß≠ Check a sample\n",
    "print(\"üîç Sample rows:\")\n",
    "print(df[[\"strava_count\", \"ecocounter_count\", \"total_count\"]].head())\n",
    "\n",
    "# üìä Summary stats\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "print(df[[\"strava_count\", \"ecocounter_count\", \"total_count\"]].describe())\n",
    "\n",
    "# üìà Correlation matrix\n",
    "print(\"\\nüìà Correlation Matrix:\")\n",
    "print(df[[\"strava_count\", \"ecocounter_count\", \"total_count\"]].corr())\n",
    "\n",
    "# --- üìâ Visualize Distributions ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[\"total_count\"], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Total Weekly Counts (Strava + EcoCounter)\")\n",
    "plt.xlabel(\"Total Weekly Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# --- üéØ Covariate Analysis ---\n",
    "covariate_cols = [\n",
    "    \"MAX_slopePct\",\n",
    "    \"Minority LandClass Pct\",\n",
    "    \"2024 Median Household Income\",\n",
    "    \"2024 Diversity Index\"\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "covariate_cols = [col for col in covariate_cols if col in df.columns]\n",
    "\n",
    "print(\"\\nüß≠ Found covariates:\", covariate_cols)\n",
    "\n",
    "# Correlation with counts\n",
    "correlation_results = df[[\"strava_count\", \"ecocounter_count\", \"total_count\"] + covariate_cols].corr()\n",
    "print(\"\\nüìà Covariate correlations with counts:\")\n",
    "print(correlation_results.loc[covariate_cols, [\"strava_count\", \"ecocounter_count\", \"total_count\"]])\n",
    "\n",
    "# --- üìä Visualize Covariates vs. Count ---\n",
    "for cov in covariate_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=df[cov], y=df[\"total_count\"])\n",
    "    sns.regplot(x=df[cov], y=df[\"total_count\"], scatter=False, color='red', label='Trend')\n",
    "    plt.title(f\"Total Count vs. {cov}\")\n",
    "    plt.xlabel(cov)\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Load Libraries ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Set Display Options ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# --- Load Data ---\n",
    "data_path = '../processed_data/weekly_with_covariates.csv'\n",
    "df = pd.read_csv(data_path, parse_dates=['week_start'])\n",
    "\n",
    "# --- Rename columns for clarity ---\n",
    "df = df.rename(columns={\n",
    "    'SUM_total_trip_count': 'strava_count',\n",
    "    'EcoCntr_weekly_SUM': 'ecocounter_count'\n",
    "})\n",
    "df['total_count'] = df['strava_count'] + df['ecocounter_count']\n",
    "\n",
    "# --- Identify numeric covariates ---\n",
    "excluded_cols = ['GRID_ID', 'week_start', 'strava_count', 'ecocounter_count', 'total_count']\n",
    "covariate_cols = [col for col in df.columns if col not in excluded_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# --- Top 10 locations by average total activity ---\n",
    "top_locations = df.groupby('GRID_ID')[['strava_count', 'ecocounter_count', 'total_count']].mean()\n",
    "top_locations = top_locations.sort_values('total_count', ascending=False).reset_index()\n",
    "print(\"üåç Top 10 Grid Cells by Average Total Count:\")\n",
    "print(top_locations.head(10))\n",
    "\n",
    "# --- Covariate correlation matrix ---\n",
    "print(\"\\nüìà Covariate Correlations with Total Counts:\")\n",
    "correlations = df[covariate_cols + ['strava_count', 'ecocounter_count', 'total_count']].corr()\n",
    "print(correlations[['strava_count', 'ecocounter_count', 'total_count']].loc[covariate_cols].sort_values('total_count', ascending=False))\n",
    "\n",
    "# --- Pairplot for top correlated covariates ---\n",
    "top_covs = correlations['total_count'].abs().sort_values(ascending=False).head(5).index.tolist()\n",
    "if top_covs:\n",
    "    sns.pairplot(df, vars=top_covs + ['total_count'])\n",
    "    plt.suptitle(\"üìä Pairplot of Top Covariates with Total Count\", y=1.02)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No strong covariates found for pairplot.\")\n",
    "\n",
    "# --- Time series trend for Strava vs EcoCounter ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_weekly = df.groupby('week_start')[['strava_count', 'ecocounter_count', 'total_count']].mean()\n",
    "df_weekly.plot(ax=plt.gca())\n",
    "plt.title(\"üìÜ Weekly Mean Counts: Strava vs EcoCounter\")\n",
    "plt.xlabel(\"Week Start Date\")\n",
    "plt.ylabel(\"Average Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Boxplot of counts by slope class (if available) ---\n",
    "if 'slopePct' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='slopePct', y='total_count')\n",
    "    plt.title(\"üì¶ Total Count by Slope Category\")\n",
    "    plt.xlabel(\"Slope Category\")\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'slopePct' column not found in the data.\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- üìÅ Load Data ---\n",
    "data_path = '../processed_data/weekly_with_covariates.csv'\n",
    "df = pd.read_csv(data_path, parse_dates=['week_start'])\n",
    "\n",
    "# --- ‚úÖ Rename Columns for Simplicity ---\n",
    "df = df.rename(columns={\n",
    "    'SUM_total_trip_count': 'strava_count',\n",
    "    'EcoCntr_weekly_SUM': 'ecocounter_count'\n",
    "})\n",
    "df['total_count'] = df['strava_count'] + df['ecocounter_count']\n",
    "\n",
    "# --- üîç Preview ---\n",
    "print(\"‚úÖ File loaded successfully.\")\n",
    "print(df[['GRID_ID', 'week_start', 'strava_count', 'ecocounter_count', 'total_count']].head())\n",
    "\n",
    "# --- üìà Summary Stats ---\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "print(df[['strava_count', 'ecocounter_count', 'total_count']].describe())\n",
    "\n",
    "# --- üîó Correlation Matrix ---\n",
    "print(\"\\nüìà Correlation Matrix:\")\n",
    "print(df[['strava_count', 'ecocounter_count', 'total_count']].corr())\n",
    "\n",
    "# --- üó∫Ô∏è Top 10 Grid Cells by Mean Counts ---\n",
    "grouped = df.groupby('GRID_ID')[['strava_count', 'ecocounter_count', 'total_count']].mean().reset_index()\n",
    "top_grids = grouped.sort_values('total_count', ascending=False).head(10)\n",
    "print(\"\\nüåç Top 10 Grid Cells by Average Total Count:\")\n",
    "print(top_grids)\n",
    "\n",
    "# --- üìâ Plot Trends for Top Grids ---\n",
    "top_ids = top_grids['GRID_ID'].tolist()\n",
    "df_top = df[df['GRID_ID'].isin(top_ids)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=df_top, x='week_start', y='total_count', hue='GRID_ID')\n",
    "plt.title('üìà Weekly Total Count for Top 10 Grid Cells')\n",
    "plt.xlabel('Week Start')\n",
    "plt.ylabel('Total Count')\n",
    "plt.legend(title='GRID_ID')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- üß≠ Covariate Exploration ---\n",
    "covariates = [\n",
    "    'MAX_slopePct', 'Minority LandClass Pct',\n",
    "    '2024 Median Household Income', '2024 Diversity Index'\n",
    "]\n",
    "covariates = [col for col in covariates if col in df.columns]\n",
    "print(\"\\nüß≠ Found covariates:\", covariates)\n",
    "\n",
    "# --- üìä Covariate Correlations ---\n",
    "correlations = df[covariates + ['strava_count', 'ecocounter_count', 'total_count']].corr()\n",
    "print(\"\\nüìà Covariate correlations with counts:\")\n",
    "print(correlations.loc[covariates, ['strava_count', 'ecocounter_count', 'total_count']])\n",
    "\n",
    "# --- üñºÔ∏è Visualize Covariate Relationships ---\n",
    "for cov in covariates:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(data=df, x=cov, y='total_count', alpha=0.5)\n",
    "    sns.regplot(data=df, x=cov, y='total_count', scatter=False, color='red')\n",
    "    plt.title(f'Total Count vs. {cov}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# --- üìÅ Load Data ---\n",
    "df = pd.read_csv('../processed_data/weekly_with_covariates.csv', parse_dates=['week_start'])\n",
    "\n",
    "# --- ‚úÖ Rename for simplicity ---\n",
    "df = df.rename(columns={\n",
    "    'SUM_total_trip_count': 'strava_count',\n",
    "    'EcoCntr_weekly_SUM': 'ecocounter_count'\n",
    "})\n",
    "df['total_count'] = df['strava_count'] + df['ecocounter_count']\n",
    "\n",
    "# --- üßπ Clean and Convert Slope Category to Numeric Midpoint ---\n",
    "df['MAX_slopePct'] = df['MAX_slopePct'].astype(str).str.replace('‚Äì', '-', regex=False).str.strip()\n",
    "slope_bins = {\n",
    "    '0 to 1%': 0.5,\n",
    "    '1 to 3%': 2.0,\n",
    "    '3 to 6%': 4.5,\n",
    "    '6 to 8%': 7.0,\n",
    "    '8 to 12%': 10.0,\n",
    "    '12 to 25%': 18.5,\n",
    "    'Above 25%': 30.0\n",
    "}\n",
    "df['MAX_slopePct'] = df['MAX_slopePct'].replace(slope_bins)\n",
    "df['MAX_slopePct'] = pd.to_numeric(df['MAX_slopePct'], errors='coerce')\n",
    "\n",
    "# --- üî¢ Convert Other Covariates ---\n",
    "df['2024 Median Household Income'] = pd.to_numeric(df['2024 Median Household Income'], errors='coerce')\n",
    "df['2024 Diversity Index'] = pd.to_numeric(df['2024 Diversity Index'], errors='coerce')\n",
    "\n",
    "# --- ‚ùì Missing values report ---\n",
    "print(\"\\n‚ùì Missing values before modeling:\")\n",
    "print(df[['strava_count', 'MAX_slopePct', '2024 Median Household Income', '2024 Diversity Index', 'ecocounter_count']].isna().sum())\n",
    "\n",
    "# --- üß† Multivariate Regression ---\n",
    "features = ['strava_count', 'MAX_slopePct', '2024 Median Household Income', '2024 Diversity Index']\n",
    "df_model = df.dropna(subset=features + ['ecocounter_count'])\n",
    "\n",
    "if not df_model.empty:\n",
    "    X = df_model[features]\n",
    "    y = df_model['ecocounter_count']\n",
    "\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "    print(\"\\nüî¢ Multivariate Regression Results:\")\n",
    "    print(f\"  R¬≤ Score: {r2_score(y, y_pred):.3f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(\"  Coefficients:\")\n",
    "    for feat, coef in zip(features, model.coef_):\n",
    "        print(f\"    {feat}: {coef:.2f}\")\n",
    "    print(f\"  Intercept: {model.intercept_:.2f}\")\n",
    "else:\n",
    "    print(\"\\nüö´ No valid rows for modeling after cleaning.\")\n",
    "\n",
    "# --- üìà Seasonal Breakdown ---\n",
    "df['month'] = df['week_start'].dt.month\n",
    "monthly_avg = df.groupby('month')[['strava_count', 'ecocounter_count', 'total_count']].mean()\n",
    "\n",
    "monthly_avg.plot(marker='o', figsize=(10, 5))\n",
    "plt.title('üìÜ Average Monthly Bicycle Counts (2019‚Äì2023)')\n",
    "plt.ylabel('Average Weekly Count')\n",
    "plt.xlabel('Month')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- üåç Spatial Clustering & Mapping ---\n",
    "df_grid = df.groupby('GRID_ID')[['strava_count', 'ecocounter_count', 'total_count']].mean().reset_index()\n",
    "\n",
    "# Cluster grid cells by usage\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_grid['cluster'] = kmeans.fit_predict(df_grid[['strava_count', 'ecocounter_count']])\n",
    "\n",
    "# Assign mock coordinates for demo purposes\n",
    "df_grid['lat'] = 36.3 + (np.arange(len(df_grid)) % 20) * 0.01\n",
    "df_grid['lon'] = -94.3 + (np.arange(len(df_grid)) // 20) * 0.01\n",
    "\n",
    "# Create folium map\n",
    "m = folium.Map(location=[36.37, -94.21], zoom_start=10)\n",
    "for _, row in df_grid.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=5 + row['total_count'] / 5000,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_opacity=0.6,\n",
    "        popup=(f\"GRID: {row['GRID_ID']}<br>\"\n",
    "               f\"Strava: {row['strava_count']:.0f}<br>\"\n",
    "               f\"EcoCounter: {row['ecocounter_count']:.0f}<br>\"\n",
    "               f\"Cluster: {row['cluster']}\")\n",
    "    ).add_to(m)\n",
    "\n",
    "m.save('../processed_data/spatial_clusters_map.html')\n",
    "print(\"\\nüó∫Ô∏è Interactive map saved: spatial_clusters_map.html\")\n",
    "\n",
    "# --- üíæ Save Cleaned Data ---\n",
    "df.to_csv('../processed_data/df_cleaned.csv', index=False)\n",
    "print(\"‚úÖ Cleaned dataset saved as df_cleaned.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Load Data ---\n",
    "df = pd.read_csv('../processed_data/weekly_with_covariates.csv', parse_dates=['week_start'])\n",
    "\n",
    "# --- Rename columns ---\n",
    "df = df.rename(columns={\n",
    "    'SUM_total_trip_count': 'strava_count',\n",
    "    'EcoCntr_weekly_SUM': 'ecocounter_count'\n",
    "})\n",
    "df['total_count'] = df['strava_count'] + df['ecocounter_count']\n",
    "\n",
    "# --- Convert slope category to numeric ---\n",
    "df['MAX_slopePct'] = df['MAX_slopePct'].astype(str).str.replace('‚Äì', '-', regex=False).str.strip()\n",
    "slope_bins = {\n",
    "    '0 to 1%': 0.5,\n",
    "    '1 to 3%': 2.0,\n",
    "    '3 to 6%': 4.5,\n",
    "    '6 to 8%': 7.0,\n",
    "    '8 to 12%': 10.0,\n",
    "    '12 to 25%': 18.5,\n",
    "    'Above 25%': 30.0\n",
    "}\n",
    "df['MAX_slopePct'] = df['MAX_slopePct'].replace(slope_bins)\n",
    "df['MAX_slopePct'] = pd.to_numeric(df['MAX_slopePct'], errors='coerce')\n",
    "\n",
    "# --- Convert other covariates to numeric ---\n",
    "df['2024 Median Household Income'] = pd.to_numeric(df['2024 Median Household Income'], errors='coerce')\n",
    "df['2024 Diversity Index'] = pd.to_numeric(df['2024 Diversity Index'], errors='coerce')\n",
    "\n",
    "# --- Drop rows with missing predictor or target ---\n",
    "features = ['strava_count', 'MAX_slopePct', '2024 Median Household Income', '2024 Diversity Index']\n",
    "df_model = df.dropna(subset=features + ['ecocounter_count'])\n",
    "\n",
    "# --- Regression (All Data) ---\n",
    "if not df_model.empty:\n",
    "    X = df_model[features]\n",
    "    y = df_model['ecocounter_count']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    print(\"Multivariate Regression Results (All Data):\")\n",
    "    print(f\"  R¬≤ Score: {r2_score(y, y_pred):.3f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.2f}\")\n",
    "    print(\"  Coefficients:\")\n",
    "    for feat, coef in zip(features, model.coef_):\n",
    "        print(f\"    {feat}: {coef:.2f}\")\n",
    "    print(f\"  Intercept: {model.intercept_:.2f}\")\n",
    "else:\n",
    "    print(\"No valid rows for modeling after cleaning.\")\n",
    "\n",
    "# --- Seasonal Breakdown Plot ---\n",
    "df['month'] = df['week_start'].dt.month\n",
    "monthly_avg = df.groupby('month')[['strava_count', 'ecocounter_count', 'total_count']].mean()\n",
    "\n",
    "monthly_avg.plot(marker='o', figsize=(10, 5))\n",
    "plt.title('Average Monthly Bicycle Counts (2019‚Äì2023)')\n",
    "plt.ylabel('Average Weekly Count')\n",
    "plt.xlabel('Month')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Spatial Clustering ---\n",
    "df_grid = df.groupby('GRID_ID')[['strava_count', 'ecocounter_count', 'total_count']].mean().reset_index()\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_grid['cluster'] = kmeans.fit_predict(df_grid[['strava_count', 'ecocounter_count']])\n",
    "df_grid['lat'] = 36.3 + (np.arange(len(df_grid)) % 20) * 0.01\n",
    "df_grid['lon'] = -94.3 + (np.arange(len(df_grid)) // 20) * 0.01\n",
    "\n",
    "m = folium.Map(location=[36.37, -94.21], zoom_start=10)\n",
    "for _, row in df_grid.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=5 + row['total_count'] / 5000,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_opacity=0.6,\n",
    "        popup=(f\"GRID: {row['GRID_ID']}<br>\"\n",
    "               f\"Strava: {row['strava_count']:.0f}<br>\"\n",
    "               f\"EcoCounter: {row['ecocounter_count']:.0f}<br>\"\n",
    "               f\"Cluster: {row['cluster']}\")\n",
    "    ).add_to(m)\n",
    "m.save('../processed_data/spatial_clusters_map.html')\n",
    "print(\"Interactive map saved: spatial_clusters_map.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
